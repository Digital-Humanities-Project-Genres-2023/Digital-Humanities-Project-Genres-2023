{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2effbf29",
   "metadata": {},
   "source": [
    "### Standard Model Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b5e557a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from contextualized_topic_models.models.ctm import CombinedTM\n",
    "from contextualized_topic_models.utils.data_preparation import TopicModelDataPreparation\n",
    "from contextualized_topic_models.utils.preprocessing import WhiteSpacePreprocessingStopwords\n",
    "import nltk\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27aebefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from src import puhti_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90d48d0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read in dataset dev.csv. Set param 'data' to 'dev', 'test' or 'train' if you want another dataset.\n"
     ]
    }
   ],
   "source": [
    "### Load in data\n",
    "df = puhti_files.genre_data_to_pandas(data=\"dev\", add_labels=True, merge_ecco=True, better_subcat_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39b20e1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "### Sample data for faster training\n",
    "### Stratified with main_category to ensure that all categories are included\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "df, _ = train_test_split(df, train_size=30, stratify=df['main_category'], random_state=123)\n",
    "\n",
    "print(len(df[\"main_category\"].unique()))\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5f3e2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Read in texts\n",
    "\n",
    "df[\"text\"] = df[\"document_id\"].apply(lambda x: puhti_files.read_text_file(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de4596a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25312"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Create dataset with splitted documents. Document_id is kept for later merge.\n",
    "\n",
    "def split_text(text, num_words):\n",
    "    words = text.split()\n",
    "    chunks = [' '.join(words[i:i + num_words]) for i in range(0, len(words), num_words)]\n",
    "    return chunks\n",
    "\n",
    "num_words = 128\n",
    "split_data = []\n",
    "for _, row in df.iterrows():\n",
    "    doc_id = row['document_id']\n",
    "    text = row['text']\n",
    "    chunks = split_text(text, num_words)\n",
    "    \n",
    "    for chunk in chunks:\n",
    "        split_data.append({'document_id': doc_id, 'text': chunk})\n",
    "\n",
    "split_df = pd.DataFrame(split_data)\n",
    "len(split_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c48cd54f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /users/tturpein/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "### Setting up stuff for the model. Details not important for this example.\n",
    "\n",
    "from nltk.corpus import stopwords as stop_words\n",
    "nltk.download('stopwords')\n",
    "stopwords = list(stop_words.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f4f8b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Preprocess texts\n",
    "### !!!NOTE: This function drops rows if processed document is empty. We need to keep this in mind when joining data back later\n",
    "### We'll use the \"retained_indices\" later\n",
    "\n",
    "sp = WhiteSpacePreprocessingStopwords(list(split_df[\"text\"]), stopwords_list=stopwords, vocabulary_size=2000)\n",
    "preprocessed_documents, unpreprocessed_corpus, vocab, retained_indices = sp.preprocess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "322b9b6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25312\n",
      "25310\n",
      "25310\n"
     ]
    }
   ],
   "source": [
    "### As can be seen from the lenghts, the preprocessing function has dropped rows\n",
    "### The original data now has more rows\n",
    "### Because the rows can be dropped from anywhere, the data don't match directly anymore\n",
    "\n",
    "print(len(split_df))\n",
    "print(len(preprocessed_documents))\n",
    "print(len(unpreprocessed_corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "74a3481c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d373692c6b7042aabdb93d753683cd8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Data Preparation\n",
    "\n",
    "tp = TopicModelDataPreparation(\"all-mpnet-base-v2\")\n",
    "training_dataset = tp.fit(text_for_contextual=unpreprocessed_corpus, text_for_bow=preprocessed_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9207cbeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/tturpein/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 40 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch: [10/10]\t Seen Samples: [252800/253100]\tTrain Loss: 250.24247251100178\tTime: 0:00:07.497389: : 10it [01:14,  7.41s/it]\n",
      "100%|██████████| 396/396 [00:06<00:00, 59.28it/s] \n"
     ]
    }
   ],
   "source": [
    "### Fitting the model. Using 10 topics here. Number not important for the example but variable used later.\n",
    "\n",
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\" # Gets rid of warnings\n",
    "\n",
    "topics = 10\n",
    "ctm = CombinedTM(bow_size=len(tp.vocab), contextual_size=768, n_components=topics, num_epochs=10)\n",
    "ctm.fit(training_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7afc81",
   "metadata": {},
   "source": [
    "### Combining the Predictions for the Original Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "69a1079a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 396/396 [00:06<00:00, 58.51it/s] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(25310, 10)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Topic predictions as percentages for each topic for each document chunk\n",
    "\n",
    "topics_predictions = ctm.get_thetas(training_dataset, n_samples=5)\n",
    "topics_predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c3617e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Adding the predictions to a dataframe\n",
    "topic_columns = [f\"topic_{i}_prob\" for i in range(0, topics)]\n",
    "predictions_df = pd.DataFrame(topics_predictions, columns=topic_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "30cddf47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25312, 12)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### !!!NOTE: Because of dropped rows, the precictions dataframe doesn't match split_df\n",
    "### retained_indices has the actual indices of the data. We use that to reset the index after which we can concat correctly\n",
    "\n",
    "#Resetting the index \n",
    "predictions_df = predictions_df.set_index(pd.Index(retained_indices))\n",
    "split_df = pd.concat([split_df, predictions_df], axis=1)\n",
    "split_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f76e5ad7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document_id</th>\n",
       "      <th>text</th>\n",
       "      <th>topic_0_prob</th>\n",
       "      <th>topic_1_prob</th>\n",
       "      <th>topic_2_prob</th>\n",
       "      <th>topic_3_prob</th>\n",
       "      <th>topic_4_prob</th>\n",
       "      <th>topic_5_prob</th>\n",
       "      <th>topic_6_prob</th>\n",
       "      <th>topic_7_prob</th>\n",
       "      <th>topic_8_prob</th>\n",
       "      <th>topic_9_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25307</th>\n",
       "      <td>0229201100</td>\n",
       "      <td>height: They steal wine who take it, When he's...</td>\n",
       "      <td>0.197272</td>\n",
       "      <td>0.079634</td>\n",
       "      <td>0.028550</td>\n",
       "      <td>0.038391</td>\n",
       "      <td>0.030669</td>\n",
       "      <td>0.303124</td>\n",
       "      <td>0.051662</td>\n",
       "      <td>0.029097</td>\n",
       "      <td>0.203182</td>\n",
       "      <td>0.038421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25308</th>\n",
       "      <td>0229201100</td>\n",
       "      <td>do its duty. Wine was the only Helicon, Whence...</td>\n",
       "      <td>0.020584</td>\n",
       "      <td>0.018548</td>\n",
       "      <td>0.036269</td>\n",
       "      <td>0.040286</td>\n",
       "      <td>0.036530</td>\n",
       "      <td>0.396715</td>\n",
       "      <td>0.037054</td>\n",
       "      <td>0.063699</td>\n",
       "      <td>0.336634</td>\n",
       "      <td>0.013680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25309</th>\n",
       "      <td>0229201100</td>\n",
       "      <td>thesis allow, You're a cuckold, fays the, do I...</td>\n",
       "      <td>0.297308</td>\n",
       "      <td>0.035864</td>\n",
       "      <td>0.024246</td>\n",
       "      <td>0.034924</td>\n",
       "      <td>0.101646</td>\n",
       "      <td>0.056621</td>\n",
       "      <td>0.036701</td>\n",
       "      <td>0.037634</td>\n",
       "      <td>0.168228</td>\n",
       "      <td>0.206828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25310</th>\n",
       "      <td>0229201100</td>\n",
       "      <td>Beauty by constraint poffefling, You enjoy but...</td>\n",
       "      <td>0.011740</td>\n",
       "      <td>0.083752</td>\n",
       "      <td>0.019720</td>\n",
       "      <td>0.016546</td>\n",
       "      <td>0.005298</td>\n",
       "      <td>0.467611</td>\n",
       "      <td>0.089696</td>\n",
       "      <td>0.020196</td>\n",
       "      <td>0.266411</td>\n",
       "      <td>0.019028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25311</th>\n",
       "      <td>0229201100</td>\n",
       "      <td>but ill occasion; We only meet to celebrate Th...</td>\n",
       "      <td>0.199441</td>\n",
       "      <td>0.108153</td>\n",
       "      <td>0.032220</td>\n",
       "      <td>0.027070</td>\n",
       "      <td>0.052341</td>\n",
       "      <td>0.172780</td>\n",
       "      <td>0.087749</td>\n",
       "      <td>0.029083</td>\n",
       "      <td>0.185904</td>\n",
       "      <td>0.105259</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      document_id                                               text  \\\n",
       "25307  0229201100  height: They steal wine who take it, When he's...   \n",
       "25308  0229201100  do its duty. Wine was the only Helicon, Whence...   \n",
       "25309  0229201100  thesis allow, You're a cuckold, fays the, do I...   \n",
       "25310  0229201100  Beauty by constraint poffefling, You enjoy but...   \n",
       "25311  0229201100  but ill occasion; We only meet to celebrate Th...   \n",
       "\n",
       "       topic_0_prob  topic_1_prob  topic_2_prob  topic_3_prob  topic_4_prob  \\\n",
       "25307      0.197272      0.079634      0.028550      0.038391      0.030669   \n",
       "25308      0.020584      0.018548      0.036269      0.040286      0.036530   \n",
       "25309      0.297308      0.035864      0.024246      0.034924      0.101646   \n",
       "25310      0.011740      0.083752      0.019720      0.016546      0.005298   \n",
       "25311      0.199441      0.108153      0.032220      0.027070      0.052341   \n",
       "\n",
       "       topic_5_prob  topic_6_prob  topic_7_prob  topic_8_prob  topic_9_prob  \n",
       "25307      0.303124      0.051662      0.029097      0.203182      0.038421  \n",
       "25308      0.396715      0.037054      0.063699      0.336634      0.013680  \n",
       "25309      0.056621      0.036701      0.037634      0.168228      0.206828  \n",
       "25310      0.467611      0.089696      0.020196      0.266411      0.019028  \n",
       "25311      0.172780      0.087749      0.029083      0.185904      0.105259  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### There shouldn't be prediction data for the missing rows\n",
    "### First we just check the tail, so that the predictions didn't just concat from the top\n",
    "### The tail should have proper data provided that they weren't the rows that were dropped\n",
    "\n",
    "split_df.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "88a0ef24",
   "metadata": {},
   "outputs": [],
   "source": [
    "### We obtain the indices of the rows that were dropped\n",
    "### If there is a gap in retained_indices, then that row was dropped\n",
    "### Note: this function doesn't work for sequential missing rows, but that's not a huge concern here\n",
    "\n",
    "missing_rows = []\n",
    "last = -1\n",
    "for i in retained_indices:\n",
    "    if last != (i-1):\n",
    "        missing_rows.append(i-1)\n",
    "    last = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a96292aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document_id</th>\n",
       "      <th>text</th>\n",
       "      <th>topic_0_prob</th>\n",
       "      <th>topic_1_prob</th>\n",
       "      <th>topic_2_prob</th>\n",
       "      <th>topic_3_prob</th>\n",
       "      <th>topic_4_prob</th>\n",
       "      <th>topic_5_prob</th>\n",
       "      <th>topic_6_prob</th>\n",
       "      <th>topic_7_prob</th>\n",
       "      <th>topic_8_prob</th>\n",
       "      <th>topic_9_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1243</th>\n",
       "      <td>0581801300</td>\n",
       "      <td>viginti, r. triginta. F IN IS.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21241</th>\n",
       "      <td>0644700500</td>\n",
       "      <td>I I S. ·.:, ;' \". ..</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      document_id                            text  topic_0_prob  topic_1_prob  \\\n",
       "1243   0581801300  viginti, r. triginta. F IN IS.           NaN           NaN   \n",
       "21241  0644700500            I I S. ·.:, ;' \". ..           NaN           NaN   \n",
       "\n",
       "       topic_2_prob  topic_3_prob  topic_4_prob  topic_5_prob  topic_6_prob  \\\n",
       "1243            NaN           NaN           NaN           NaN           NaN   \n",
       "21241           NaN           NaN           NaN           NaN           NaN   \n",
       "\n",
       "       topic_7_prob  topic_8_prob  topic_9_prob  \n",
       "1243            NaN           NaN           NaN  \n",
       "21241           NaN           NaN           NaN  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Checking the indices where rows were dropped. These shouldn't have prediction data\n",
    "\n",
    "split_df.loc[missing_rows]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "be7efaf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic_0_prob</th>\n",
       "      <th>topic_1_prob</th>\n",
       "      <th>topic_2_prob</th>\n",
       "      <th>topic_3_prob</th>\n",
       "      <th>topic_4_prob</th>\n",
       "      <th>topic_5_prob</th>\n",
       "      <th>topic_6_prob</th>\n",
       "      <th>topic_7_prob</th>\n",
       "      <th>topic_8_prob</th>\n",
       "      <th>topic_9_prob</th>\n",
       "      <th>best_topic</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>document_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0005100101</th>\n",
       "      <td>0.075802</td>\n",
       "      <td>0.045416</td>\n",
       "      <td>0.066427</td>\n",
       "      <td>0.051594</td>\n",
       "      <td>0.042904</td>\n",
       "      <td>0.132047</td>\n",
       "      <td>0.352835</td>\n",
       "      <td>0.085567</td>\n",
       "      <td>0.103216</td>\n",
       "      <td>0.044192</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0011900103</th>\n",
       "      <td>0.058763</td>\n",
       "      <td>0.055537</td>\n",
       "      <td>0.085053</td>\n",
       "      <td>0.043430</td>\n",
       "      <td>0.041303</td>\n",
       "      <td>0.055415</td>\n",
       "      <td>0.061347</td>\n",
       "      <td>0.513766</td>\n",
       "      <td>0.045237</td>\n",
       "      <td>0.040149</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0018900102</th>\n",
       "      <td>0.084326</td>\n",
       "      <td>0.053208</td>\n",
       "      <td>0.094333</td>\n",
       "      <td>0.062360</td>\n",
       "      <td>0.050234</td>\n",
       "      <td>0.124165</td>\n",
       "      <td>0.333803</td>\n",
       "      <td>0.096352</td>\n",
       "      <td>0.051314</td>\n",
       "      <td>0.049904</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             topic_0_prob  topic_1_prob  topic_2_prob  topic_3_prob  \\\n",
       "document_id                                                           \n",
       "0005100101       0.075802      0.045416      0.066427      0.051594   \n",
       "0011900103       0.058763      0.055537      0.085053      0.043430   \n",
       "0018900102       0.084326      0.053208      0.094333      0.062360   \n",
       "\n",
       "             topic_4_prob  topic_5_prob  topic_6_prob  topic_7_prob  \\\n",
       "document_id                                                           \n",
       "0005100101       0.042904      0.132047      0.352835      0.085567   \n",
       "0011900103       0.041303      0.055415      0.061347      0.513766   \n",
       "0018900102       0.050234      0.124165      0.333803      0.096352   \n",
       "\n",
       "             topic_8_prob  topic_9_prob  best_topic  \n",
       "document_id                                          \n",
       "0005100101       0.103216      0.044192           6  \n",
       "0011900103       0.045237      0.040149           7  \n",
       "0018900102       0.051314      0.049904           6  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Now we can continue with ordinary matters\n",
    "### Calculate mean probability from chunks for each document\n",
    "### Then take the best probability as 'best_topic'\n",
    "### This reduces the dataframe back to 1 document_id per row\n",
    "\n",
    "mean_prob_df = split_df.groupby('document_id')[topic_columns].mean()\n",
    "mean_prob_df['best_topic'] = mean_prob_df.idxmax(axis=1).str.replace('_prob', '').str.replace('topic_', '').astype(int)\n",
    "print(len(mean_prob_df))\n",
    "mean_prob_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "84a1aca9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document_id</th>\n",
       "      <th>work_id</th>\n",
       "      <th>main_category</th>\n",
       "      <th>sub_category</th>\n",
       "      <th>main_category_label</th>\n",
       "      <th>sub_category_label</th>\n",
       "      <th>publication_year</th>\n",
       "      <th>gatherings</th>\n",
       "      <th>total_price</th>\n",
       "      <th>publication_place</th>\n",
       "      <th>...</th>\n",
       "      <th>topic_1_prob</th>\n",
       "      <th>topic_2_prob</th>\n",
       "      <th>topic_3_prob</th>\n",
       "      <th>topic_4_prob</th>\n",
       "      <th>topic_5_prob</th>\n",
       "      <th>topic_6_prob</th>\n",
       "      <th>topic_7_prob</th>\n",
       "      <th>topic_8_prob</th>\n",
       "      <th>topic_9_prob</th>\n",
       "      <th>best_topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0373000300</td>\n",
       "      <td>174-lucubrations of isaac bickerstaff</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>Literature</td>\n",
       "      <td>Other fiction</td>\n",
       "      <td>1710</td>\n",
       "      <td>12mo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>London</td>\n",
       "      <td>...</td>\n",
       "      <td>0.071519</td>\n",
       "      <td>0.101755</td>\n",
       "      <td>0.064900</td>\n",
       "      <td>0.060920</td>\n",
       "      <td>0.158996</td>\n",
       "      <td>0.223581</td>\n",
       "      <td>0.095156</td>\n",
       "      <td>0.063433</td>\n",
       "      <td>0.068418</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0128501700</td>\n",
       "      <td>60-gentle shepherd</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Arts</td>\n",
       "      <td>Music, hymns, songs</td>\n",
       "      <td>1769</td>\n",
       "      <td>12mo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Edinburgh</td>\n",
       "      <td>...</td>\n",
       "      <td>0.075439</td>\n",
       "      <td>0.060078</td>\n",
       "      <td>0.055638</td>\n",
       "      <td>0.035147</td>\n",
       "      <td>0.408412</td>\n",
       "      <td>0.063354</td>\n",
       "      <td>0.040143</td>\n",
       "      <td>0.107057</td>\n",
       "      <td>0.060486</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0581801300</td>\n",
       "      <td>15584-life of william of wykeham bishop of win...</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>History</td>\n",
       "      <td>Biographical History</td>\n",
       "      <td>1759</td>\n",
       "      <td>8vo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>London</td>\n",
       "      <td>...</td>\n",
       "      <td>0.178303</td>\n",
       "      <td>0.131627</td>\n",
       "      <td>0.047478</td>\n",
       "      <td>0.052422</td>\n",
       "      <td>0.082215</td>\n",
       "      <td>0.062230</td>\n",
       "      <td>0.227451</td>\n",
       "      <td>0.060814</td>\n",
       "      <td>0.052888</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  document_id                                            work_id  \\\n",
       "0  0373000300              174-lucubrations of isaac bickerstaff   \n",
       "1  0128501700                                 60-gentle shepherd   \n",
       "2  0581801300  15584-life of william of wykeham bishop of win...   \n",
       "\n",
       "   main_category  sub_category main_category_label    sub_category_label  \\\n",
       "0              2            18          Literature         Other fiction   \n",
       "1              0             1                Arts   Music, hymns, songs   \n",
       "2              4            10             History  Biographical History   \n",
       "\n",
       "  publication_year gatherings  total_price publication_place  ...  \\\n",
       "0             1710       12mo          NaN            London  ...   \n",
       "1             1769       12mo          NaN         Edinburgh  ...   \n",
       "2             1759        8vo          NaN            London  ...   \n",
       "\n",
       "  topic_1_prob topic_2_prob topic_3_prob  topic_4_prob  topic_5_prob  \\\n",
       "0     0.071519     0.101755     0.064900      0.060920      0.158996   \n",
       "1     0.075439     0.060078     0.055638      0.035147      0.408412   \n",
       "2     0.178303     0.131627     0.047478      0.052422      0.082215   \n",
       "\n",
       "   topic_6_prob  topic_7_prob  topic_8_prob  topic_9_prob  best_topic  \n",
       "0      0.223581      0.095156      0.063433      0.068418           6  \n",
       "1      0.063354      0.040143      0.107057      0.060486           5  \n",
       "2      0.062230      0.227451      0.060814      0.052888           7  \n",
       "\n",
       "[3 rows x 24 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Finally merge to original dataframe\n",
    "df = pd.merge(df, mean_prob_df, on='document_id', how='left')\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02bc46ed",
   "metadata": {},
   "source": [
    "### Extra: Comparing to premade categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "170ea103",
   "metadata": {},
   "outputs": [],
   "source": [
    "### We can also try fit our own topics to the premade categories in a way which results in greatest accuracy\n",
    "### In my tests the accuracy is usually quite low, not that it necessarily matters\n",
    "\n",
    "### Note: There might be also an error in the code here because there's a bit of copy-paste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "079d0c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "36113f20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 2, 0, 0, 2, 0],\n",
       "       [1, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 2, 5, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "       [1, 0, 0, 0, 0, 0, 0, 3, 0, 0],\n",
       "       [0, 0, 1, 0, 0, 0, 0, 1, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
       "       [0, 0, 1, 0, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 1, 0, 2, 0, 0, 0, 1, 0, 0]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = confusion_matrix(df['main_category'], df['best_topic'])\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0316ed9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Algorithm which determines best fit\n",
    "row_ind, col_ind = linear_sum_assignment(-cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e0b40153",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{5: 2, 0: 0, 6: 4, 9: 6, 7: 8, 2: 1, 1: 9, 4: 3, 8: 7, 3: 5}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Map from created topics to old\n",
    "topic_mapping = {i: df['main_category'].unique()[j] for i, j in zip(col_ind, row_ind)}\n",
    "topic_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4ef06cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Add the mapped topics to dataframe\n",
    "df['mapped_topic'] = df['best_topic'].map(topic_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b5343406",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.10\n"
     ]
    }
   ],
   "source": [
    "### Gets accuracy of how many new topics == old topics\n",
    "accuracy = np.mean(df['main_category'] == df['mapped_topic'])\n",
    "print(f\"Accuracy: {accuracy:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
