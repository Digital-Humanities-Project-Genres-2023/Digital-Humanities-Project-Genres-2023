{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df9fd163",
   "metadata": {},
   "source": [
    "### Example of SuperCTM Model\n",
    "- In SuperCTM, you can label the documents to aid the clustering\n",
    "- One way would be to utilise the pre-provided categories (used here)\n",
    "- One could also label a subset of data by hand as a seed data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "012c974a",
   "metadata": {},
   "source": [
    "### CTM Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4dc15b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### GENERAL VARIABLES:\n",
    "sample_size = 100\n",
    "epochs = 10\n",
    "\n",
    "#What categories to use, either main/10 or sub_cat/43 if you want proper fit for comparison\n",
    "#This is really for the extra stuff at the end\n",
    "topics = 10\n",
    "compare_to = \"main_category\" #main_category#sub_category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa7dd508",
   "metadata": {},
   "outputs": [],
   "source": [
    "from contextualized_topic_models.models.ctm import CombinedTM\n",
    "from contextualized_topic_models.utils.data_preparation import TopicModelDataPreparation\n",
    "from contextualized_topic_models.utils.preprocessing import WhiteSpacePreprocessingStopwords\n",
    "import nltk\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7de23b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from src import puhti_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c6c4f43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read in dataset train.csv. Set param 'data' to 'dev', 'test' or 'train' if you want another dataset.\n"
     ]
    }
   ],
   "source": [
    "### Load in data\n",
    "df = puhti_files.genre_data_to_pandas(data=\"train\", add_labels=True, merge_ecco=True, better_subcat_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7de69b27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "#Sample data, ensure that every category is represented\n",
    "\n",
    "import math\n",
    "n_categories = len(df[compare_to].unique())\n",
    "take_per_category = math.ceil(sample_size / n_categories)\n",
    "\n",
    "\n",
    "# Group by sub_category and take one random sample from each group\n",
    "df = df.groupby(compare_to, group_keys=False).apply(lambda x: x.sample(take_per_category, replace=True))\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "print(len(df[compare_to].unique()))\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fac472ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document_id</th>\n",
       "      <th>work_id</th>\n",
       "      <th>main_category</th>\n",
       "      <th>sub_category</th>\n",
       "      <th>main_category_label</th>\n",
       "      <th>sub_category_label</th>\n",
       "      <th>publication_year</th>\n",
       "      <th>gatherings</th>\n",
       "      <th>total_price</th>\n",
       "      <th>publication_place</th>\n",
       "      <th>author_id</th>\n",
       "      <th>other_actors</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23320</th>\n",
       "      <td>0569102600</td>\n",
       "      <td>10017-battle of hastings</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Arts</td>\n",
       "      <td>Theatre, plays, opera</td>\n",
       "      <td>1778</td>\n",
       "      <td>12mo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dublin</td>\n",
       "      <td>76451457</td>\n",
       "      <td>robertmarchbank_2</td>\n",
       "      <td>TIHE //\"/*: - /s/ /'\\nBattle of Hastings,\\n\\nA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1494</th>\n",
       "      <td>1096600100</td>\n",
       "      <td>9-hymns</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Arts</td>\n",
       "      <td>Music, hymns, songs</td>\n",
       "      <td>1790</td>\n",
       "      <td>12mo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>London</td>\n",
       "      <td>19686646</td>\n",
       "      <td>68548720</td>\n",
       "      <td>IH Y N S\\n\\nO F\\nINTE RCESSION\\n\\nFOR\\nALL MAN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6931</th>\n",
       "      <td>0733800500</td>\n",
       "      <td>513-funeral or grief a-la-mode</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Arts</td>\n",
       "      <td>Theatre, plays, opera</td>\n",
       "      <td>1790</td>\n",
       "      <td>12mo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>London</td>\n",
       "      <td>22167754</td>\n",
       "      <td>NV4420</td>\n",
       "      <td>THE FUtNERAL;\\n\\nGRIEF A-L4- AI D R,\\n\\nC OMED...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      document_id                         work_id  main_category  \\\n",
       "23320  0569102600        10017-battle of hastings              0   \n",
       "1494   1096600100                         9-hymns              0   \n",
       "6931   0733800500  513-funeral or grief a-la-mode              0   \n",
       "\n",
       "       sub_category main_category_label     sub_category_label  \\\n",
       "23320             0                Arts  Theatre, plays, opera   \n",
       "1494              1                Arts    Music, hymns, songs   \n",
       "6931              0                Arts  Theatre, plays, opera   \n",
       "\n",
       "      publication_year gatherings  total_price publication_place author_id  \\\n",
       "23320             1778       12mo          NaN            Dublin  76451457   \n",
       "1494              1790       12mo          NaN            London  19686646   \n",
       "6931              1790       12mo          NaN            London  22167754   \n",
       "\n",
       "            other_actors                                               text  \n",
       "23320  robertmarchbank_2  TIHE //\"/*: - /s/ /'\\nBattle of Hastings,\\n\\nA...  \n",
       "1494            68548720  IH Y N S\\n\\nO F\\nINTE RCESSION\\n\\nFOR\\nALL MAN...  \n",
       "6931              NV4420  THE FUtNERAL;\\n\\nGRIEF A-L4- AI D R,\\n\\nC OMED...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Read in texts\n",
    "\n",
    "df[\"text\"] = df[\"document_id\"].apply(lambda x: puhti_files.read_text_file(x))\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af549e93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66782"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Create dataset with splitted documents. Document_id is kept for later merge.\n",
    "\n",
    "def split_text(text, num_words):\n",
    "    words = text.split()\n",
    "    chunks = [' '.join(words[i:i + num_words]) for i in range(0, len(words), num_words)]\n",
    "    return chunks\n",
    "\n",
    "num_words = 128\n",
    "split_data = []\n",
    "for _, row in df.iterrows():\n",
    "    doc_id = row['document_id']\n",
    "    main_category_label = row[\"main_category_label\"]\n",
    "    sub_category_label = row[\"sub_category_label\"]\n",
    "    \n",
    "    text = row['text']\n",
    "    chunks = split_text(text, num_words)\n",
    "    \n",
    "    for chunk in chunks:\n",
    "        split_data.append({\n",
    "            'document_id': doc_id,\n",
    "            \"main_category_label\": main_category_label,\n",
    "            \"sub_category_label\": sub_category_label,\n",
    "            'text': chunk\n",
    "        })\n",
    "\n",
    "split_df = pd.DataFrame(split_data)\n",
    "len(split_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d478070",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /users/tturpein/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords as stop_words\n",
    "nltk.download('stopwords')\n",
    "stopwords = list(stop_words.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f61c4169",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66765\n",
      "66765\n"
     ]
    }
   ],
   "source": [
    "sp = WhiteSpacePreprocessingStopwords(list(split_df[\"text\"]), stopwords_list=stopwords, vocabulary_size=2000)#vocabulary_size=2000\n",
    "preprocessed_documents, unpreprocessed_corpus, vocab, retained_indices = sp.preprocess()\n",
    "print(len(preprocessed_documents))\n",
    "print(len(unpreprocessed_corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e3de4142",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use \"_label\" column as labels.\n",
    "# I'm not sure if the actual names really matter. Could be that you can use numeric ones.\n",
    "labels = split_df[compare_to + \"_label\"].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0d2ecf70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66765"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We have to drop the labels for the rows that the preprocessing drops\n",
    "labels = labels[retained_indices]\n",
    "labels = list(labels)\n",
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b1d11b79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a864d545b163406b887c7ffb41168ffa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/334 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tp = TopicModelDataPreparation(\"paraphrase-multilingual-mpnet-base-v2\")\n",
    "\n",
    "training_dataset = tp.fit(\n",
    "    text_for_contextual = unpreprocessed_corpus,\n",
    "    text_for_bow = preprocessed_documents,\n",
    "    labels = labels\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f247f51b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Checking how labels are encoded\n",
    "### They should be one-hotted\n",
    "training_dataset.__getitem__(0)[\"labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f2f76930",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Training the model with labels\n",
    "\n",
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\" # Gets rid of warnings\n",
    "\n",
    "ctm = CombinedTM(\n",
    "    bow_size=len(tp.vocab),\n",
    "    contextual_size=768,\n",
    "    n_components=topics,\n",
    "    num_epochs=epochs,\n",
    "    label_size=len(set(labels))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a566a467",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/tturpein/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 40 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch: [10/10]\t Seen Samples: [667520/667650]\tTrain Loss: 246.76384887987908\tTime: 0:00:13.549540: : 10it [02:19, 13.92s/it]\n",
      "100%|██████████| 1044/1044 [00:11<00:00, 92.58it/s]\n"
     ]
    }
   ],
   "source": [
    "ctm.fit(training_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "996187ca",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1044/1044 [00:12<00:00, 83.29it/s] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(66765, 10)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Topic predictions as percentages for each topic for each document chunk\n",
    "\n",
    "topics_predictions = ctm.get_thetas(training_dataset, n_samples=5)\n",
    "topics_predictions.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20306cea",
   "metadata": {},
   "source": [
    "### Comparing to premade categories\n",
    "- The rest of the code is just a accuracy comparison to the older categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ada3d96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Adding the predictions to a dataframe\n",
    "topic_columns = [f\"topic_{i}_prob\" for i in range(0, topics)]\n",
    "predictions_df = pd.DataFrame(topics_predictions, columns=topic_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "882a1bc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(66782, 14)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### !!!NOTE: Because of dropped rows, the precictions dataframe doesn't match split_df\n",
    "### retained_indices has the actual indices of the data. We use that to reset the index after which we can concat correctly\n",
    "\n",
    "#Resetting the index \n",
    "predictions_df = predictions_df.set_index(pd.Index(retained_indices))\n",
    "split_df = pd.concat([split_df, predictions_df], axis=1)\n",
    "split_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1d17c8a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic_0_prob</th>\n",
       "      <th>topic_1_prob</th>\n",
       "      <th>topic_2_prob</th>\n",
       "      <th>topic_3_prob</th>\n",
       "      <th>topic_4_prob</th>\n",
       "      <th>topic_5_prob</th>\n",
       "      <th>topic_6_prob</th>\n",
       "      <th>topic_7_prob</th>\n",
       "      <th>topic_8_prob</th>\n",
       "      <th>topic_9_prob</th>\n",
       "      <th>best_topic</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>document_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0036000301</th>\n",
       "      <td>0.039599</td>\n",
       "      <td>0.053394</td>\n",
       "      <td>0.141056</td>\n",
       "      <td>0.052451</td>\n",
       "      <td>0.060308</td>\n",
       "      <td>0.183007</td>\n",
       "      <td>0.285934</td>\n",
       "      <td>0.084858</td>\n",
       "      <td>0.048649</td>\n",
       "      <td>0.050744</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0054600105</th>\n",
       "      <td>0.049573</td>\n",
       "      <td>0.049268</td>\n",
       "      <td>0.489403</td>\n",
       "      <td>0.053756</td>\n",
       "      <td>0.043055</td>\n",
       "      <td>0.046321</td>\n",
       "      <td>0.081896</td>\n",
       "      <td>0.086069</td>\n",
       "      <td>0.054584</td>\n",
       "      <td>0.046075</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0054902900</th>\n",
       "      <td>0.053652</td>\n",
       "      <td>0.062471</td>\n",
       "      <td>0.168312</td>\n",
       "      <td>0.059912</td>\n",
       "      <td>0.055716</td>\n",
       "      <td>0.086901</td>\n",
       "      <td>0.261915</td>\n",
       "      <td>0.079225</td>\n",
       "      <td>0.111514</td>\n",
       "      <td>0.060382</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             topic_0_prob  topic_1_prob  topic_2_prob  topic_3_prob  \\\n",
       "document_id                                                           \n",
       "0036000301       0.039599      0.053394      0.141056      0.052451   \n",
       "0054600105       0.049573      0.049268      0.489403      0.053756   \n",
       "0054902900       0.053652      0.062471      0.168312      0.059912   \n",
       "\n",
       "             topic_4_prob  topic_5_prob  topic_6_prob  topic_7_prob  \\\n",
       "document_id                                                           \n",
       "0036000301       0.060308      0.183007      0.285934      0.084858   \n",
       "0054600105       0.043055      0.046321      0.081896      0.086069   \n",
       "0054902900       0.055716      0.086901      0.261915      0.079225   \n",
       "\n",
       "             topic_8_prob  topic_9_prob  best_topic  \n",
       "document_id                                          \n",
       "0036000301       0.048649      0.050744           6  \n",
       "0054600105       0.054584      0.046075           2  \n",
       "0054902900       0.111514      0.060382           6  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Calculate mean probability from chunks for each document\n",
    "### Then take the best probability as 'best_topic'\n",
    "### This reduces the dataframe back to 1 document_id per row\n",
    "\n",
    "mean_prob_df = split_df.groupby('document_id')[topic_columns].mean()\n",
    "mean_prob_df['best_topic'] = mean_prob_df.idxmax(axis=1).str.replace('_prob', '').str.replace('topic_', '').astype(int)\n",
    "print(len(mean_prob_df))\n",
    "mean_prob_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "42208f16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document_id</th>\n",
       "      <th>work_id</th>\n",
       "      <th>main_category</th>\n",
       "      <th>sub_category</th>\n",
       "      <th>main_category_label</th>\n",
       "      <th>sub_category_label</th>\n",
       "      <th>publication_year</th>\n",
       "      <th>gatherings</th>\n",
       "      <th>total_price</th>\n",
       "      <th>publication_place</th>\n",
       "      <th>...</th>\n",
       "      <th>topic_1_prob</th>\n",
       "      <th>topic_2_prob</th>\n",
       "      <th>topic_3_prob</th>\n",
       "      <th>topic_4_prob</th>\n",
       "      <th>topic_5_prob</th>\n",
       "      <th>topic_6_prob</th>\n",
       "      <th>topic_7_prob</th>\n",
       "      <th>topic_8_prob</th>\n",
       "      <th>topic_9_prob</th>\n",
       "      <th>best_topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0569102600</td>\n",
       "      <td>10017-battle of hastings</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Arts</td>\n",
       "      <td>Theatre, plays, opera</td>\n",
       "      <td>1778</td>\n",
       "      <td>12mo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dublin</td>\n",
       "      <td>...</td>\n",
       "      <td>0.056752</td>\n",
       "      <td>0.482701</td>\n",
       "      <td>0.045842</td>\n",
       "      <td>0.055106</td>\n",
       "      <td>0.043572</td>\n",
       "      <td>0.048222</td>\n",
       "      <td>0.089947</td>\n",
       "      <td>0.085164</td>\n",
       "      <td>0.051805</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1096600100</td>\n",
       "      <td>9-hymns</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Arts</td>\n",
       "      <td>Music, hymns, songs</td>\n",
       "      <td>1790</td>\n",
       "      <td>12mo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>London</td>\n",
       "      <td>...</td>\n",
       "      <td>0.050728</td>\n",
       "      <td>0.504780</td>\n",
       "      <td>0.038393</td>\n",
       "      <td>0.039043</td>\n",
       "      <td>0.051786</td>\n",
       "      <td>0.029318</td>\n",
       "      <td>0.160318</td>\n",
       "      <td>0.047461</td>\n",
       "      <td>0.041301</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0733800500</td>\n",
       "      <td>513-funeral or grief a-la-mode</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Arts</td>\n",
       "      <td>Theatre, plays, opera</td>\n",
       "      <td>1790</td>\n",
       "      <td>12mo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>London</td>\n",
       "      <td>...</td>\n",
       "      <td>0.168704</td>\n",
       "      <td>0.151562</td>\n",
       "      <td>0.058825</td>\n",
       "      <td>0.042640</td>\n",
       "      <td>0.079528</td>\n",
       "      <td>0.106274</td>\n",
       "      <td>0.084968</td>\n",
       "      <td>0.209860</td>\n",
       "      <td>0.055933</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  document_id                         work_id  main_category  sub_category  \\\n",
       "0  0569102600        10017-battle of hastings              0             0   \n",
       "1  1096600100                         9-hymns              0             1   \n",
       "2  0733800500  513-funeral or grief a-la-mode              0             0   \n",
       "\n",
       "  main_category_label     sub_category_label publication_year gatherings  \\\n",
       "0                Arts  Theatre, plays, opera             1778       12mo   \n",
       "1                Arts    Music, hymns, songs             1790       12mo   \n",
       "2                Arts  Theatre, plays, opera             1790       12mo   \n",
       "\n",
       "   total_price publication_place  ... topic_1_prob topic_2_prob topic_3_prob  \\\n",
       "0          NaN            Dublin  ...     0.056752     0.482701     0.045842   \n",
       "1          NaN            London  ...     0.050728     0.504780     0.038393   \n",
       "2          NaN            London  ...     0.168704     0.151562     0.058825   \n",
       "\n",
       "   topic_4_prob  topic_5_prob  topic_6_prob  topic_7_prob  topic_8_prob  \\\n",
       "0      0.055106      0.043572      0.048222      0.089947      0.085164   \n",
       "1      0.039043      0.051786      0.029318      0.160318      0.047461   \n",
       "2      0.042640      0.079528      0.106274      0.084968      0.209860   \n",
       "\n",
       "   topic_9_prob  best_topic  \n",
       "0      0.051805           2  \n",
       "1      0.041301           2  \n",
       "2      0.055933           8  \n",
       "\n",
       "[3 rows x 24 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Finally merge to original dataframe\n",
    "df = pd.merge(df, mean_prob_df, on='document_id', how='left')\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4646e3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d0687022",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 8, 0, 0, 0, 0, 0, 2, 0],\n",
       "       [2, 0, 0, 0, 3, 0, 1, 0, 0, 4],\n",
       "       [0, 0, 7, 0, 0, 0, 1, 0, 1, 1],\n",
       "       [0, 2, 0, 0, 0, 2, 2, 0, 3, 1],\n",
       "       [2, 2, 0, 0, 0, 0, 5, 0, 0, 1],\n",
       "       [3, 0, 0, 7, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 5, 0, 0, 0, 2, 0, 3, 0],\n",
       "       [5, 0, 1, 0, 0, 0, 0, 0, 3, 1],\n",
       "       [0, 0, 0, 0, 0, 5, 5, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 0, 3, 1, 3, 2, 0]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = confusion_matrix(df[compare_to], df['best_topic'])\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d9fae6de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 3, 0, 5, 1, 8, 4, 9, 3, 1])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the best mapping\n",
    "best_mapping = np.argmax(cm, axis=0)\n",
    "best_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "93e654eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping_dict = {i: category for i, category in enumerate(best_mapping)}\n",
    "mapping_dict\n",
    "len(mapping_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5fdf792a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['best_fit_category'] = df['best_topic'].map(mapping_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a9d1ec1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = accuracy_score(df['main_category'], df['best_fit_category'])\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4c4852",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
